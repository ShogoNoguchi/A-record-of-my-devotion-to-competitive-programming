{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNHD7dmzYQHLl/s3nlsgzdT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShogoNoguchi/ABC_code/blob/main/%EF%BC%88%E9%80%B2%E6%8D%97%E3%83%8E%E3%83%BC%E3%83%88%E2%91%A0%EF%BC%89%EF%BD%9E%E5%A4%A7%E8%A6%8F%E6%A8%A1%E6%A7%8B%E9%80%A0%E3%81%AE%E7%89%B9%E5%AE%9A%E3%81%A8%E4%BF%AE%E6%AD%A3%E9%A0%85%E7%9B%AE%E3%81%AE%E7%99%BA%E8%A6%8B%EF%BD%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "文責：群馬大学　野口翔伍\n",
        "\n",
        "題：（進捗）～大規模構造の特定と修正項目の発見～"
      ],
      "metadata": {
        "id": "zB1PzacrXSHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Driveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR96Dz5cSUoF",
        "outputId": "c10cd01c-4d8c-42c7-9de2-d2216585813e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "論文を熟読し、GitHubのREAD MEを読んで課題1つ目を処理する方法を調べた。\n",
        "TUAB・TUEVどちらのデータセットを使っても良いと思ったが、どちらもTemple Universityへの要求方法が不明なため、質問済。\n",
        "➡のちに、これらは使わず、SEED-Vを用いた感情分類をすることが判明。"
      ],
      "metadata": {
        "id": "y9B--gvwROlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "リポジトリを[/content/drive/My Drive/LaBraM]へダウンロード済 12/2"
      ],
      "metadata": {
        "id": "xhc-OS48JQwd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-Gv59BL-o81",
        "outputId": "39f4926a-388d-45f7-d741-ba38c0e8f4b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "Cloning into 'labram_repo'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 124 (delta 49), reused 45 (delta 42), pack-reused 57 (from 1)\u001b[K\n",
            "Receiving objects: 100% (124/124), 167.16 MiB | 26.39 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n",
            "Updating files: 100% (27/27), done.\n",
            "ディレクトリ構造:\n",
            "LaBraM/\n",
            "  checkpoints/\n",
            "    labram-base.pth/\n",
            "    vqnsp.pth/\n",
            "  data_processor/\n",
            "    data_preprocess.py/\n",
            "    dataset.py/\n",
            "  dataset_maker/\n",
            "    make_TUAB.py/\n",
            "    make_TUEV.py/\n",
            "    make_h5dataset_for_pretrain.py/\n",
            "    shock/\n",
            "      __init__.py/\n",
            "      utils/\n",
            "        __init__.py/\n",
            "        eegUtils.py/\n",
            "        h5.py/\n",
            "        ringBuffer.py/\n",
            "  engine_for_finetuning.py/\n",
            "  engine_for_pretraining.py/\n",
            "  engine_for_vqnsp.py/\n",
            "  labram.png/\n",
            "  modeling_finetune.py/\n",
            "  modeling_pretrain.py/\n",
            "  modeling_vqnsp.py/\n",
            "  norm_ema_quantizer.py/\n",
            "  optim_factory.py/\n",
            "  README.md/\n",
            "  requirements.txt/\n",
            "  run_class_finetuning.py/\n",
            "  run_labram_pretraining.py/\n",
            "  run_vqnsp_training.py/\n",
            "  utils.py/\n",
            "\n",
            "[checkpoints]フォルダの内容:\n",
            "  labram-base.pth\n",
            "  vqnsp.pth\n"
          ]
        }
      ],
      "source": [
        "# Google Driveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 保存先ディレクトリの設定\n",
        "import os\n",
        "drive_path = '/content/drive/My Drive/LaBraM'  # Drive内に保存するフォルダ名\n",
        "if not os.path.exists(drive_path):\n",
        "    os.makedirs(drive_path)\n",
        "\n",
        "# リポジトリをクローン\n",
        "repo_url = \"https://github.com/935963004/LaBraM.git\"  # GitHubのURL\n",
        "%cd /content\n",
        "!git clone {repo_url} labram_repo\n",
        "!cp -r labram_repo/* \"{drive_path}\"\n",
        "\n",
        "# ディレクトリ構造を表示\n",
        "import os\n",
        "\n",
        "def display_directory_structure(path, level=0):\n",
        "    indent = \"  \" * level\n",
        "    print(f\"{indent}{os.path.basename(path)}/\")\n",
        "    if os.path.isdir(path):\n",
        "        for item in os.listdir(path):\n",
        "            display_directory_structure(os.path.join(path, item), level + 1)\n",
        "\n",
        "print(\"ディレクトリ構造:\")\n",
        "display_directory_structure(drive_path)\n",
        "\n",
        "# 推奨ファイルを特定するために 'checkpoints' フォルダの内容を表示\n",
        "checkpoints_dir = os.path.join(drive_path, 'checkpoints')\n",
        "if os.path.exists(checkpoints_dir):\n",
        "    print(\"\\n[checkpoints]フォルダの内容:\")\n",
        "    for file in os.listdir(checkpoints_dir):\n",
        "        print(f\"  {file}\")\n",
        "else:\n",
        "    print(\"\\n[checkpoints]フォルダが存在しません。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "大規模コードの木構造を特定 12/3"
      ],
      "metadata": {
        "id": "SfaPrArmER3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ファインチューニング時にはGiTHubの以下のコマンドにより\n",
        "run_class_finetuning.pyが最初に起動される。"
      ],
      "metadata": {
        "id": "GGdteki6Kw8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OMP_NUM_THREADS=1 torchrun --nnodes=1 --nproc_per_node=8 run_class_finetuning.py \\\n",
        "        --output_dir ./checkpoints/finetune_tuab_base/ \\\n",
        "        --log_dir ./log/finetune_tuab_base \\\n",
        "        --model labram_base_patch200_200 \\\n",
        "        --finetune ./checkpoints/labram-base.pth \\    #baseモデルの重み\n",
        "        --weight_decay 0.05 \\\n",
        "        --batch_size 64 \\\n",
        "        --lr 5e-4 \\\n",
        "        --update_freq 1 \\\n",
        "        --warmup_epochs 3 \\\n",
        "        --epochs 30 \\\n",
        "        --layer_decay 0.65 \\\n",
        "        --drop_path 0.1 \\\n",
        "        --dist_eval \\\n",
        "        --save_ckpt_freq 5 \\\n",
        "        --disable_rel_pos_bias \\\n",
        "        --abs_pos_emb \\\n",
        "        --dataset TUAB \\   #データセット名の指定\n",
        "        --disable_qkv_bias \\\n",
        "        --seed 0"
      ],
      "metadata": {
        "id": "6GFLZizLMgK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "run_class_finetuning.pyから、以下の依存関係を特定した。"
      ],
      "metadata": {
        "id": "i24SlkJsMivZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下は、run_class_finetuning.py が依存しているコード群・クラス・関数を「文字による木構造」で示したものです（上から下に向かって依存が深まります）。また、run_class_finetuning.py 内の主要な関数呼び出しを、どのコード・関数へ依存しているかを付記します。実際には、importなどで多くの関数やクラスが呼ばれますが、特に本質的な依存先をまずは明確化します。"
      ],
      "metadata": {
        "id": "hSLhqYw3umSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_class_finetuning.py\n",
        "├─ get_args() : argparseによる引数パースを行い、ds_init（deepspeed初期化用）も取得\n",
        "│\n",
        "├─ main(args, ds_init)\n",
        "│  ├─ utils.init_distributed_mode(args)\n",
        "│  │   └─ torch.distributed (PyTorch公式)\n",
        "│\n",
        "│  ├─ (ds_initが有効な場合) utils.create_ds_config(args) : DeepSpeed用設定ファイル生成\n",
        "│\n",
        "│  ├─ get_dataset(args)\n",
        "│  │   ├─ if args.dataset == 'TUAB': utils.prepare_TUAB_dataset(\"path/to/TUAB\")\n",
        "│  │   │    └─ utils.py 内のprepare_TUAB_dataset関数\n",
        "│  │   ├─ if args.dataset == 'TUEV': utils.prepare_TUEV_dataset(\"path/to/TUEV\")\n",
        "│  │   │    └─ utils.py 内のprepare_TUEV_dataset関数\n",
        "│  │   └─ 上記関数でDataLoader構築に必要なDatasetクラスを使用（TUABLoader/TUEVLoader, utils内）\n",
        "│\n",
        "│  ├─ get_models(args)\n",
        "│  │   ├─ timm.models.create_model(args.model, ...)\n",
        "│  │   │   ├─ modeling_finetune.py 内で@register_modelされたモデル(labram_base_patch200_200等)がtimmのレジストリ経由で作成\n",
        "│  │   │   ├─ NeuralTransformerクラス (modeling_finetune.py)\n",
        "│  │   │   └─ Attention / Block / PatchEmbed 等 (modeling_finetune.py 内で定義)\n",
        "│\n",
        "│  ├─ モデル読み込み・重みロード\n",
        "│  │   └─ utils.load_state_dict(...)\n",
        "│\n",
        "│  ├─ Optimizer / Scheduler関連設定\n",
        "│  │   └─ optim_factory.py の create_optimizer, get_parameter_groups 関数\n",
        "│\n",
        "│  ├─ 損失関数 (BCEWithLogitsLoss, CrossEntropyLoss等 : PyTorch公式)\n",
        "│\n",
        "│  ├─ utils.auto_load_model(args, model, ...)\n",
        "│\n",
        "│  ├─ トレーニングループ\n",
        "│  │   ├─ for epoch in range(args.epochs):\n",
        "│  │   │   ├─ train_one_epoch(...)\n",
        "│  │   │   │   ├─ engine_for_finetuning.py の train_one_epoch関数\n",
        "│  │   │   │   ├─ 内部でmodel(...)呼び出し (modeling_finetune.pyのNeuralTransformer.forward)\n",
        "│  │   │   │   ├─ utils.get_metrics(...) for accuracyなど (utils.py)\n",
        "│  │   │   └─ evaluate(...)\n",
        "│  │   │       ├─ engine_for_finetuning.py の evaluate関数\n",
        "│  │   │       └─ 内部で同様にmodel(...)呼び出し, utils.get_metrics(...)呼び出し\n",
        "│\n",
        "│  ├─ utils.save_model(...)でチェックポイント保存\n",
        "│  └─ 全エポック終了後、時間計測などログ出力\n",
        "│\n",
        "└─ if __name__ == '__main__':\n",
        "   ├─ opts, ds_init = get_args()\n",
        "   └─ main(opts, ds_init)\n"
      ],
      "metadata": {
        "id": "fngewK7Hu1c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "さらに詳しくは以下のようになります。"
      ],
      "metadata": {
        "id": "gEJwTUcVu4Af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_class_finetuning.py\n",
        "├── argparse (標準ライブラリ)\n",
        "├── datetime (標準ライブラリ)\n",
        "├── numpy (外部ライブラリ)\n",
        "├── time (標準ライブラリ)\n",
        "├── torch (外部ライブラリ)\n",
        "│   ├── torch.backends.cudnn\n",
        "│   ├── torch.utils.data\n",
        "│   └── torch.nn\n",
        "├── json (標準ライブラリ)\n",
        "├── os (標準ライブラリ)\n",
        "├── pathlib.Path (標準ライブラリ)\n",
        "├── collections.OrderedDict (標準ライブラリ)\n",
        "├── timm (外部ライブラリ)\n",
        "│   ├── timm.data.mixup.Mixup\n",
        "│   ├── timm.models.create_model   #モデル構造を入れて、モデルを出力\n",
        "│   ├── timm.loss.LabelSmoothingCrossEntropy\n",
        "│   ├── timm.loss.SoftTargetCrossEntropy\n",
        "│   └── timm.utils.ModelEma\n",
        "├── optim_factory.py     #最適化関連\n",
        "│   ├── create_optimizer\n",
        "│   ├── get_parameter_groups\n",
        "│   └── LayerDecayValueAssigner\n",
        "├── engine_for_finetuning.py  #ファインチューニング用のエンジン\n",
        "│   ├── train_one_epoch\n",
        "│   └── evaluate\n",
        "├── utils.py\n",
        "│   ├── NativeScalerWithGradNormCount   #学習率スケーリング\n",
        "│   ├── init_distributed_mode\n",
        "│   ├── create_ds_config\n",
        "│   ├── get_rank\n",
        "│   ├── cosine_scheduler\n",
        "│   ├── auto_load_model\n",
        "│   ├── save_model\n",
        "│   ├── is_main_process\n",
        "│   ├── prepare_TUAB_dataset   #ここを変える必要がある。 utils内のprepare_oo_dataset系\n",
        "│   ├── prepare_TUEV_dataset\n",
        "│   ├── TensorboardLogger\n",
        "│   └── load_state_dict\n",
        "├── modeling_finetune.py    #ここを調べるとファインチューニングのモデル構造が分かる・変更できる。\n",
        "│   └── モデルの定義\n",
        "├── scipy.interpolate (外部ライブラリ)  #これはなんでインポートされてるか分からない...\n"
      ],
      "metadata": {
        "id": "VVOXJZstMu0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12/4 run_class_finetuning.pyの実行時の関数呼び出し順序（木構造）"
      ],
      "metadata": {
        "id": "U-4XpUs2OGy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ファインチューニング実行時のコード実行順序(ざっくりしたフロー)"
      ],
      "metadata": {
        "id": "fBMzePy9vF0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "README中のfinetune用コマンドは以下であった。"
      ],
      "metadata": {
        "id": "4uRCBTdlvHqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OMP_NUM_THREADS=1 torchrun --nnodes=1 --nproc_per_node=8 run_class_finetuning.py \\\n",
        "        --output_dir ./checkpoints/finetune_tuab_base/ \\\n",
        "        --log_dir ./log/finetune_tuab_base \\\n",
        "        --model labram_base_patch200_200 \\\n",
        "        --finetune ./checkpoints/labram-base.pth \\\n",
        "        --weight_decay 0.05 \\\n",
        "        --batch_size 64 \\\n",
        "        --lr 5e-4 \\\n",
        "        --update_freq 1 \\\n",
        "        --warmup_epochs 3 \\\n",
        "        --epochs 30 \\\n",
        "        --layer_decay 0.65 \\\n",
        "        --drop_path 0.1 \\\n",
        "        --dist_eval \\\n",
        "        --save_ckpt_freq 5 \\\n",
        "        --disable_rel_pos_bias \\\n",
        "        --abs_pos_emb \\\n",
        "        --dataset TUAB \\\n",
        "        --disable_qkv_bias \\\n",
        "        --seed 0"
      ],
      "metadata": {
        "id": "HiH3Cqx1vOKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記コマンドを動かしたとき、主な処理フロー（時間的順序）は以下の通り。"
      ],
      "metadata": {
        "id": "lVaDLiGBviaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1. run_class_finetuning.py が実行される\n",
        "   ├─ get_args()で引数をパース\n",
        "   ├─ ds_initが必要ならDeepSpeed設定\n",
        "   └─ main(args, ds_init)を呼び出す\n",
        "\n",
        "2. main(args, ds_init):\n",
        "   ├─ utils.init_distributed_mode(args)で分散学習設定 (MPI or env var)\n",
        "   ├─ ds_initがある場合：utils.create_ds_config(args)でDeepSpeed用ファイル生成\n",
        "   ├─ get_dataset(args)呼び出し\n",
        "   │  ├─ args.datasetが'TUAB'の場合: utils.prepare_TUAB_dataset(...)実行\n",
        "   │  ├─ 得られたtrain/val/test datasetをDataLoader化\n",
        "   ├─ get_models(args)でモデル構築\n",
        "   │  ├─ timm.create_model(args.model)がmodeling_finetune.py内のNeuralTransformerインスタンス化\n",
        "   ├─ 事前学習済みチェックポイント(--finetune指定)をutils.load_state_dictでモデルにロード\n",
        "   ├─ optim_factory.create_optimizer(...)でOptimizer生成\n",
        "   ├─ 損失関数、学習率スケジューラ、weight decayスケジューラなど設定\n",
        "   ├─ utils.auto_load_model(...)で中断再開処理（過去checkpointがあればロード）\n",
        "\n",
        "3. トレーニング開始\n",
        "   ├─ for epoch in range(args.epochs):\n",
        "   │  ├─ train_one_epoch(...) (engine_for_finetuning.py)\n",
        "   │  │  ├─ DataLoaderからバッチ取得\n",
        "   │  │  ├─ model(...) forward計算\n",
        "   │  │  ├─ 損失逆伝播、optimizer.step()\n",
        "   │  │  └─ メトリクス計算 (utils.get_metrics)\n",
        "   │  ├─ evaluate(...)で検証データ推論/精度計算\n",
        "   │  ├─ 条件に応じてutils.save_model()でcheckpoint保存\n",
        "   │  └─ ログWriter(Tensorboard)更新\n",
        "\n",
        "4. 全epoch終了後、終了ログ出力しプログラム終了\n"
      ],
      "metadata": {
        "id": "UOeWQGWGvrsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "より詳しくは以下の通り。"
      ],
      "metadata": {
        "id": "4RIIhEoSvttK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_class_finetuning.py\n",
        "└── main(args, ds_init)\n",
        "    ├── utils.init_distributed_mode(args)\n",
        "    ├── デバイスとシードの設定\n",
        "    ├── cudnn.benchmark = True\n",
        "    ├── dataset_train, dataset_test, dataset_val, ch_names, metrics = get_dataset(args) #データセットの取得\n",
        "    │   └── prepare_TUAB_dataset または prepare_TUEV_dataset（utils.py内）\n",
        "    ├── サンプラーとデータローダーの設定\n",
        "    │   ├── torch.utils.data.DistributedSampler（トレーニング用）\n",
        "    │   ├── torch.utils.data.SequentialSampler（検証・テスト用）\n",
        "    │   └── torch.utils.data.DataLoader（データローダー作成）\n",
        "    ├── ロガーの設定（TensorboardLogger）\n",
        "    ├── model = get_models(args)\n",
        "    │   └── timm.models.create_model による。create_modelの中で args.modelが渡されてmodeling_finetune.py の中のモデル（labram_base_patch200_200）構造を取得する。\n",
        "    ├── モデルの初期化と読み込み   #モデルの重みがここで読まれる。\n",
        "    │   ├── 事前学習済みモデルのロード（args.finetune が指定されている場合）\n",
        "    │   ├── モデルの重みの調整（必要に応じて）\n",
        "    │   └── モデルをデバイスに転送（model.to(device)）\n",
        "    ├── モデルEMAの設定（必要に応じて）\n",
        "    ├── DistributedDataParallel の設定（分散学習の場合）\n",
        "    ├── オプティマイザとスケジューラの設定\n",
        "    │   ├── optimizer = create_optimizer(...)\n",
        "    │   ├── loss_scaler = NativeScaler()\n",
        "    │   ├── lr_schedule_values = utils.cosine_scheduler(...)\n",
        "    │   └── wd_schedule_values = utils.cosine_scheduler(...)\n",
        "    ├── 損失関数の設定（criterion）\n",
        "    ├── utils.auto_load_model(...)（チェックポイントの自動ロード）\n",
        "    ├── トレーニングループ開始（エポックごとに繰り返し）\n",
        "    │   ├── data_loader_train.sampler.set_epoch(epoch)\n",
        "    │   ├── train_stats = train_one_epoch(...)\n",
        "    │   │   ├── モデルをトレーニングモードに設定（model.train()）\n",
        "    │   │   ├── バッチごとのトレーニングループ\n",
        "    │   │   │   ├── 入力データとラベルを取得\n",
        "    │   │   │   ├── optimizer.zero_grad()\n",
        "    │   │   │   ├── 出力の計算（outputs = model(inputs)）\n",
        "    │   │   │   ├── 損失の計算（loss = criterion(outputs, targets)）\n",
        "    │   │   │   ├── loss_scaler(loss, optimizer, ...)\n",
        "    │   │   │   └── 学習率と重み減衰の更新\n",
        "    │   │   └── 統計情報の収集\n",
        "    │   ├── モデルの保存（必要に応じて）\n",
        "    │   ├── 検証（data_loader_val がある場合）\n",
        "    │   │   ├── val_stats = evaluate(...)\n",
        "    │   │   │   ├── モデルを評価モードに設定（model.eval()）\n",
        "    │   │   │   ├── バッチごとの評価ループ\n",
        "    │   │   │   │   ├── 入力データとラベルを取得\n",
        "    │   │   │   │   ├── 出力の計算（outputs = model(inputs)）\n",
        "    │   │   │   │   ├── 損失の計算（loss = criterion(outputs, targets)）\n",
        "    │   │   │   │   └── 統計情報の収集（metrics の計算）\n",
        "    │   │   └── 検証結果の表示とログ記録\n",
        "    │   ├── テスト（data_loader_test がある場合）\n",
        "    │   │   ├── test_stats = evaluate(...)\n",
        "    │   │   └── テスト結果の表示とログ記録\n",
        "    │   ├── 最良モデルの保存（必要に応じて）\n",
        "    │   └── エポックごとのログの保存\n",
        "    └── トレーニング時間の計測と表示\n"
      ],
      "metadata": {
        "id": "C_noGJx1OMVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "分類対象の数を変えたいときはモデルのヘッドを変えないといけない、まずモデル構造の変えかたを調べよう。"
      ],
      "metadata": {
        "id": "WsT0zzsshtKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "ーーーモデル構造についてーーー\n",
        "\n",
        "modeling_finetune.pyの中でtimm の @register_model デコレーターを用いて、カスタムモデル(labram_base_patch200_200)が登録されています。\n",
        "\n",
        "args.model = 'labram_base_patch200_200'となってる影響で、\n",
        "\n",
        "get_model関数＝create_modelの引数をargs.model とすると。labram_base_patch200_200 構造をtimmのcreate_modelが作ってくれる仕組み。\n",
        "以下modeling_finetuneで独自モデルが登録されてる様子。\n",
        "\n",
        "（NeuralTransformerはLaBramの本体的クラス）"
      ],
      "metadata": {
        "id": "z11zrHPoTCKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@register_model\n",
        "def labram_base_patch200_200(pretrained=False, **kwargs):\n",
        "    model = NeuralTransformer(\n",
        "        patch_size=200, embed_dim=200, depth=12, num_heads=10, mlp_ratio=4,\n",
        "        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "OYE17ZkkdP0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "ーーーーーーーーーーーーーー\n",
        "\n",
        "run_class_finetuning.pyの\n",
        "main関数内でモデルは以下のようにロードされる。\n",
        "以下のコードは、モデルの構造（modeling_finetune.py で定義された構造）に合わせてチェックポイントからロードした重みを調整する仕組みになっている。\n",
        "特に、ロードした重みの形状が現在のモデル構造と一致しない場合には、該当部分の重みを削除して適用されないようにしている点が特徴。\n",
        "\n",
        "つまり、元のLaBramの自己教師モデルの重みのヘッド部分を強制的に消して、クラス分類へ適用するようになってる。\n"
      ],
      "metadata": {
        "id": "j5QZgNobdPFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_models(args)  #モデル生成。 get_modelsはrun_class_finetuning中で定義\n",
        "\n",
        "    patch_size = model.patch_size\n",
        "    print(\"Patch size = %s\" % str(patch_size))\n",
        "    args.window_size = (1, args.input_size // patch_size)\n",
        "    args.patch_size = patch_size\n",
        "\n",
        "    if args.finetune:\n",
        "        if args.finetune.startswith('https'):\n",
        "            checkpoint = torch.hub.load_state_dict_from_url(\n",
        "                args.finetune, map_location='cpu', check_hash=True)\n",
        "        else:\n",
        "            checkpoint = torch.load(args.finetune, map_location='cpu')\n",
        "\n",
        "        print(\"Load ckpt from %s\" % args.finetune)\n",
        "        checkpoint_model = None\n",
        "        for model_key in args.model_key.split('|'):\n",
        "            if model_key in checkpoint:\n",
        "                checkpoint_model = checkpoint[model_key]\n",
        "                print(\"Load state_dict by model_key = %s\" % model_key)\n",
        "                break\n",
        "        if checkpoint_model is None:\n",
        "            checkpoint_model = checkpoint\n",
        "        if (checkpoint_model is not None) and (args.model_filter_name != ''):\n",
        "            all_keys = list(checkpoint_model.keys())\n",
        "            new_dict = OrderedDict()\n",
        "            for key in all_keys:\n",
        "                if key.startswith('student.'):\n",
        "                    new_dict[key[8:]] = checkpoint_model[key]\n",
        "                else:\n",
        "                    pass\n",
        "            checkpoint_model = new_dict\n",
        "\n",
        "        state_dict = model.state_dict()\n",
        "        for k in ['head.weight', 'head.bias']:\n",
        "            if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
        "                print(f\"Removing key {k} from pretrained checkpoint\")\n",
        "                del checkpoint_model[k]\n",
        "\n",
        "        all_keys = list(checkpoint_model.keys())\n",
        "        for key in all_keys:\n",
        "            if \"relative_position_index\" in key:\n",
        "                checkpoint_model.pop(key)\n",
        "\n",
        "        utils.load_state_dict(model, checkpoint_model, prefix=args.model_prefix)\n"
      ],
      "metadata": {
        "id": "YtRAge0MTF_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get_models\n",
        "\n",
        "\n",
        "def get_models(args):\n",
        "  #create_model は、PyTorch Image Models (timm) ライブラリが提供するユーティリティ関数で、モデルを簡単に生成するための関数です。\n",
        "    model = create_model(\n",
        "        args.model,\n",
        "        pretrained=False,\n",
        "        num_classes=args.nb_classes,  #分類クラス数\n",
        "#ドロップアウト率\n",
        "        drop_rate=args.drop,\n",
        "        drop_path_rate=args.drop_path,\n",
        "        attn_drop_rate=args.attn_drop_rate,\n",
        "        drop_block_rate=None,\n",
        "\n",
        "        use_mean_pooling=args.use_mean_pooling,\n",
        "        init_scale=args.init_scale,\n",
        "        use_rel_pos_bias=args.rel_pos_bias,\n",
        "        use_abs_pos_emb=args.abs_pos_emb,\n",
        "        init_values=args.layer_scale_init_value,\n",
        "        qkv_bias=args.qkv_bias,\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "QHKhyogRiTf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "以上から、私がもし分類数を変えたければ、args.nb_classesの値（後述するget_dataset(args)内で指定）を変えればいいことが分かる。\n",
        "\n",
        "もし分類ヘッドが希望するものに対応してなければ、modeling_finetune.py内の分類ヘッドを変えればいいだろう。"
      ],
      "metadata": {
        "id": "L0edGTHveCZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12/5\n",
        "\n",
        "ここまで分かったことを一旦まとめて明日につなげる。\n",
        "\n",
        "まず、公式手順では、以下がファインチューニングに必須：\n",
        "\n",
        "run_class_finetuning.py：ファインチューニング実行スクリプト\n",
        "\n",
        "engine_for_finetuning.py：finetuning時のtrain/evalループ\n",
        "\n",
        "modeling_finetune.py：fine-tune用モデル定義\n",
        "optim_factory.py：最適化関連\n",
        "\n",
        "utils.py：データ準備、分散初期化、評価指標など\n",
        "\n",
        "データセット生成スクリプト(make_TUAB.pyやmake_TUEV.pyはサンプル)はデータごとに必要だが公式はTUAB/TUEVを例示している\n",
        "\n",
        "\n",
        "逆に、ファインチューニングそのものに不要な.pyは、事前学習やTokenizer学習に関わるもの、具体的には：\n",
        "\n",
        "run_vqnsp_training.py：Neural Tokenizer(VQ)の学習用\n",
        "\n",
        "run_labram_pretraining.py：LaBraM事前学習用\n",
        "\n",
        "engine_for_pretraining.py：事前学習ループ用\n",
        "\n",
        "engine_for_vqnsp.py：VQ tokenizer学習ループ用\n",
        "\n",
        "modeling_pretrain.py：事前学習用モデルアーキテクチャ定義\n",
        "\n",
        "modeling_vqnsp.py：Neural tokenizerモデル定義\n",
        "\n",
        "norm_ema_quantizer.py：Vector-Quantized表現学習用コードブック管理用\n",
        "\n",
        "dataset_maker/make_h5dataset_for_pretrain.py：事前学習用HDF5データ作成用スクリプト\n",
        "\n",
        "(TUAB,TUEV以外を使うなら)make_TUAB.py, make_TUEV.pyは厳密には不要（自分のデータセット用の類似スクリプトを作成すればよい）\n",
        "\n",
        "これらは事前学習やトークナイザ学習に必要で、すでにlabram-base.pthなどの事前学習済みモデルがある前提でfine-tuneするだけなら不要となる。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Odale7Y1v754"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "【任意データセット・任意電極位置でファインチューニングするための戦略と手順】\n",
        "\n",
        "\n",
        "①データフォーマットの統一\n",
        "\n",
        "TUAB/TUEV用にはmake_TUAB.pyやmake_TUEV.pyで前処理・HDF5 or pkl形式への変換を行っている。\n",
        "\n",
        "→ SEED-Vデータセットも同様に\"HDF5\"または同様のpklフォーマットへ変換するスクリプトmake_SEEDV.py（自作）を作る。\n",
        "\n",
        "②run_class_finetuning.pyでのデータセット読込処理対応:\n",
        "\n",
        "get_dataset(args)関数内でif args.dataset == 'SEEDV': ...のような条件分岐を追加し、prepare_SEEDV_dataset()関数（自作）を呼ぶ。\n",
        "utils.pyにprepare_SEEDV_dataset関数を定義し、SEED-V用のデータローダ（Datasetクラス）を返せるようにする。またはdataset_makerフォルダ内でTUAB/TUEVを参考にSEED-V用コードを書く。\n",
        "SEED-Vは5クラス分類なのでargs.nb_classes = 5とするか、コード内で自動設定する。\n",
        "\n",
        "③電極チャンネルセットへの対応:\n",
        "\n",
        "現状get_input_chans(ch_names)関数で10-20 systemベースのチャネルインデックスを取得している。\n",
        "任意の電極位置セットを用いる場合は、この部分をカスタマイズする必要がある。例えば、SEED-V特有のチャネル命名に合わせてutils.get_input_chans(ch_names)を修正するか、追加のパラメータを与え、マッピングルールを変更する。\n",
        "\n",
        "もしくは、modeling_finetune.py内のNeuralTransformerでパッチ分割前にチャネル数が固定想定されているなら、入力チャネル数に合わせてin_chansやout_chans設定を変更（Baseモデルは特定チャネル数を仮定しているが、必要ならモデル定義を拡張し、柔軟に対応する）。\n",
        "\n",
        "④モデル出力層の次元変更:\n",
        "\n",
        "NeuralTransformerのself.head = nn.Linear(embed_dim, num_classes)で出力クラス数を決める。\n",
        "run_class_finetuning.py内でargs.nb_classesを新たなデータセットのクラス数に合わせて設定し、モデル生成時にnum_classes=args.nb_classesを渡せばOK。\n",
        "\n",
        "⑤評価メトリクスの構築（これは必要か後でもう一回検討）\n",
        "\n",
        "SEED-Vでの実験では、Balanced Accuracyの代わりにAccuracyが使われているので、これを構築する。\n",
        "\n",
        "⑤Colabでの実行:\n",
        "\n",
        "!pip install -r requirements.txtなどで依存パッケージをインストール。\n",
        "Google Drive上にリポジトリとデータセットを配置。\n",
        "%cd /content/drive/MyDrive/LaBram/でディレクトリ移動して!python run_class_finetuning.py ...で実行。\n",
        "分散は不要な場合、--nproc_per_node=1などで単GPU実行に変更可能。\n",
        "このように手順を踏めば、任意のEEGデータセット・電極セットでfine-tuningできる。\n"
      ],
      "metadata": {
        "id": "F5hDe-KYw9bP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12/6 次に、今日は異なるデータセットに対して処理を行うために、データセットを処理する関数について調べよう。まだSEED-V等データセットは入手できていないが、処理関数の中を調べることで、EDA・前処理用関数作成を加速できる。\n",
        "\n",
        "まずはデータセットが処理される関数をたどっていく（源流を探索する）"
      ],
      "metadata": {
        "id": "FDCu_qnihnHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上述したように、run_class_finetuning関数内のmain関数で、データセットは"
      ],
      "metadata": {
        "id": "Zt55wGsliAUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train, dataset_test, dataset_val, ch_names, metrics = get_dataset(args)"
      ],
      "metadata": {
        "id": "ek-4ulrOfXxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このように得られている。 get_dataset(args)は同コード内で以下のように定義されている。"
      ],
      "metadata": {
        "id": "ekTCA0JTfYiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#この関数内に、get_dataset(args)関数内でif args.dataset == 'SEEDV': ...のような条件分岐を追加し、prepare_SEEDV_dataset()関数（自作）を呼びたい。\n",
        "\n",
        "\n",
        "def get_dataset(args):\n",
        "    if args.dataset == 'TUAB':\n",
        "        train_dataset, test_dataset, val_dataset = utils.prepare_TUAB_dataset(\"path/to/TUAB\")\n",
        "\n",
        "#utils.prepare_TUAB_dataset という記述から、prepare_TUAB_dataset 関数はutils モジュール（またはスクリプト）内に定義されていることを示しています。\n",
        "\n",
        "      #チャンネル名の指定\n",
        "        ch_names = ['EEG FP1', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', \\\n",
        "                    'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF', 'EEG A1-REF', 'EEG A2-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF', 'EEG T1-REF', 'EEG T2-REF']\n",
        "\n",
        "\n",
        "\n",
        "        ch_names = [name.split(' ')[-1].split('-')[0] for name in ch_names] #各チャンネル名を加工し、余分な情報を削除して簡潔な名前（例: 'FP1', 'FP2'）に変換\n",
        "        args.nb_classes = 1    #分類タスクのクラス数設定\n",
        "        metrics = [\"pr_auc\", \"roc_auc\", \"accuracy\", \"balanced_accuracy\"]\n",
        "    elif args.dataset == 'TUEV':       #TUABじゃなければTUEV\n",
        "        train_dataset, test_dataset, val_dataset = utils.prepare_TUEV_dataset(\"path/to/TUEV\")\n",
        "        ch_names = ['EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', \\\n",
        "                    'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF', 'EEG A1-REF', 'EEG A2-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF', 'EEG T1-REF', 'EEG T2-REF']\n",
        "        ch_names = [name.split(' ')[-1].split('-')[0] for name in ch_names]\n",
        "        args.nb_classes = 6\n",
        "        metrics = [\"accuracy\", \"balanced_accuracy\", \"cohen_kappa\", \"f1_weighted\"]\n",
        "    return train_dataset, test_dataset, val_dataset, ch_names, metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "NXDGimKmfZ8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mqBvYUtCjNsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここで、データセットによって変わる「args.nb_classesの値」に注意したい。これは、のちにmain関数内で\n",
        "args.nb_classes == 1 の場合:\n",
        "BCEWithLogitsLoss（バイナリ分類用損失関数）が使用される。\n",
        "args.nb_classes > 1 の場合:\n",
        "ラベルスムージングを伴う CrossEntropyLoss または通常の CrossEntropyLoss（多クラス分類用損失関数）が選択される。\n",
        "\n",
        "という風に影響する。"
      ],
      "metadata": {
        "id": "i6CivDbhjIBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に、データセット取得元となっているutilsのutils.prepare_TUEV_dataset(\"path/to/TUEV\")を見る。\n",
        "（我々がやりたいのは多値分類のため）"
      ],
      "metadata": {
        "id": "vYIS_LvXjaet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"以下utils.pyより。\n",
        "\"私はこれを参考にして、utils.pyにprepare_SEEDV_dataset関数を定義し、\n",
        "\"SEED-V用のデータローダ（Datasetクラス）を返せるようにする。またはdataset_makerフォルダ内でTUAB/TUEVを参考にSEED-V用コードを書く。\n",
        "\n",
        "def prepare_TUEV_dataset(root):\n",
        "    # set random seed\n",
        "    seed = 4523  #再現性を確保するために、ランダムシードを設定\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    train_files = os.listdir(os.path.join(root, \"processed_train\"))\n",
        "    val_files = os.listdir(os.path.join(root, \"processed_eval\"))\n",
        "    test_files = os.listdir(os.path.join(root, \"processed_test\"))\n",
        "\n",
        "    # prepare training and test data loader\n",
        "    #データセット固有のデータローダを使っている。\n",
        "    train_dataset = TUEVLoader(\n",
        "        os.path.join(\n",
        "            root, \"processed_train\"), train_files\n",
        "    )\n",
        "    test_dataset = TUEVLoader(\n",
        "        os.path.join(\n",
        "            root, \"processed_test\"), test_files\n",
        "    )\n",
        "    val_dataset = TUEVLoader(\n",
        "        os.path.join(\n",
        "            root, \"processed_eval\"), val_files\n",
        "    )\n",
        "    print(len(train_files), len(val_files), len(test_files))\n",
        "    return train_dataset, test_dataset, val_dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "8xhKnhnwj1e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SEED-V固有のデータローダも作る必要がある。\n",
        "以下TUEVLoader."
      ],
      "metadata": {
        "id": "8-vhnWvlzo-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"utils.py\n",
        "class TUEVLoader(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, files, sampling_rate=200):\n",
        "        self.root = root\n",
        "        self.files = files\n",
        "        self.default_rate = 200\n",
        "        self.sampling_rate = sampling_rate\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = pickle.load(open(os.path.join(self.root, self.files[index]), \"rb\"))\n",
        "        X = sample[\"signal\"]\n",
        "        if self.sampling_rate != self.default_rate:\n",
        "            X = resample(X, 5 * self.sampling_rate, axis=-1)\n",
        "        Y = int(sample[\"label\"][0] - 1)\n",
        "        X = torch.FloatTensor(X)\n",
        "        return X, Y\n",
        "\n"
      ],
      "metadata": {
        "id": "-eN6qza81H9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ykuCisoi1gyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12/6\n",
        "今日やる事：\n",
        "SEED-Vデータセットも同様に\"HDF5\"または同様のpklフォーマットへ変換するスクリプトmake_SEEDV.py（自作）を作る。\n",
        "\n",
        "ここからは一旦このノートの記録を停止する。"
      ],
      "metadata": {
        "id": "YJ6snKXR2JVF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "thwH5IPQ2ZoV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}